{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"logo.png\", width=100, ALIGN=\"left\">\n",
    "<center>\n",
    "<h1>Mini Projets 2019-2020 (Info 232)</h1>\n",
    "Isabelle Guyon <br>\n",
    "info232@chalearn.org <br>\n",
    "</center>\n",
    "<span style=\"color:red\"> <h1> 2 . Pandas </h1> </span>\n",
    "    \n",
    "We have now a dataset of pictures of REAL apples and bananas, preprocessed in 4 different representations:\n",
    "- one with only 2 features (<b>R</b>edness and <b>E</b>longation) called <b>RE_data.csv</b>\n",
    "- one with only 21 features (<b>C</b>olor and <b>S</b>hape features) called <b>CS_data.csv</b>\n",
    "- one with 14580 features (all pixels of 81x69x3 <b>raw</b> images) called <b>RAW_data.csv</b>\n",
    "- one with 3072 features (all pixels of 32x32x3 <b>crop</b>ped images) called <b>CROP_data.csv</b>.\n",
    "\n",
    "We will compare the performances of various classifiers on those 4 datasets. Thus, we are going to start doing \"real\" POM: Probability, Optimization, and Modeling. We will proceed in a \"greedy\" way, eliminating some non promising avenues as we go, and not revisiting them for the moment:\n",
    "\n",
    "1. Which dataset version should we keep? Should we or not scale variables (using variable standardization)?\n",
    "2. Which learning machine of a standard toolkit (scikit-learn) is most promising?\n",
    "\n",
    "</div>\n",
    "<div style=\"background:#FFFFAA\">\n",
    "    \n",
    " This TP gives you 5 points if you answer well ALL 5 questions. If you cannot fisnish, get help by attending the Wednesday session.\n",
    "    \n",
    "<span style=\"color:red\"> <b>Save your notebook often with menu File + Save and Checkpoint.</b>\n",
    "<br> <b>Before you push your homework to your GitHub repo, use  Kernel + Restart and Run all.</b>\n",
    "</span>\n",
    "    </div>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load general libraries\n",
    "import os, re\n",
    "from glob import glob as ls\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### Add path to the sample code so the notebook finds it:\n",
    "code_dir = 'code/'                        \n",
    "from sys import path; path.append(code_dir)\n",
    "from utilities import *\n",
    "# Import code that checks your answers\n",
    "from checker import check \n",
    "# Disable some warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Select data representation\n",
    "Which dataset version should we keep? Should we do or not a variable standardization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 0: Examine the data directory\n",
    "Go to the directory `mini-dataset/`. You should find four data files ending with `.csv`. In an editor, open `RL_data.csv` or another of the data files to see how it looks like. The dataset is formatted in the CSV format (comma separated file). The examples are in lines and the features are separated by commas. The first line is the header. \n",
    "\n",
    "Examine all 4 datasets and note the number of lines and columns. Notice that they all have a different number of features but the same number of examples. \n",
    "\n",
    "It is somewhat easier to write a Python program to do this work for you. Check how the function `check_datasets` is written by typing `??check_datasets` in a new cell. Verify with an editor that this is the same code that is found in the directory `code/` in the file `utilities.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./mini-dataset/CROP_data.csv',\n",
       " './mini-dataset/CS_data.csv',\n",
       " './mini-dataset/RAW_data.csv',\n",
       " './mini-dataset/RE_data.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the datasets\n",
    "data_dir = './mini-dataset/'\n",
    "data_list = ls(data_dir + '*_data.csv')\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>num. examples</th>\n",
       "      <th>num. features</th>\n",
       "      <th>num. apples</th>\n",
       "      <th>num. bananas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CROP</td>\n",
       "      <td>491</td>\n",
       "      <td>3073</td>\n",
       "      <td>333</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS</td>\n",
       "      <td>491</td>\n",
       "      <td>22</td>\n",
       "      <td>333</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAW</td>\n",
       "      <td>491</td>\n",
       "      <td>14581</td>\n",
       "      <td>333</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RE</td>\n",
       "      <td>491</td>\n",
       "      <td>3</td>\n",
       "      <td>333</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  num. examples  num. features  num. apples  num. bananas\n",
       "0    CROP            491           3073          333           158\n",
       "1      CS            491             22          333           158\n",
       "2     RAW            491          14581          333           158\n",
       "3      RE            491              3          333           158"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataset sizes\n",
    "check_datasets(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Show the code of check_datasets.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "??check_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Load and visualize data with Pandas (review)\n",
    "In previous classes we have have started using `Numpy arrays`and `Pandas dataframes`. We now explore Pandas a little bit further. Pandas dataframes are also arrays, but a different kind of python object that Numpy arrays. They have more properties, supporting fancy database functions and having quite a few display functions and nice simple summary statistics, <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\">check the documentation</a>. Learning about Pandas will help a lot the <i>visualization binome</i>.\n",
    "\n",
    "First, you will perform these steps:\n",
    "* Call to UNIX command `!head ./mini-dataset/RE_data.csv` to view the first few lines of the file. The character `!` allows you to \"escape\" from the Jupyter notebook to the UNIX shell.\n",
    "* Load `RL_data.csv` as a pandas dataframe called `df`. Show the first few lines using the method `head`.\n",
    "* Compute simple statistics using the method `describe`.\n",
    "* Show the heat map. If you do not remember from the previous TP, think of using a search engine and type the keywords: \"pandas heatmap\". I found <a href=\"https://stackoverflow.com/questions/12286607/making-heatmap-from-pandas-dataframe\">this post</a>, for instance. \n",
    "* Create a new data frame called `df_scaled` obtained by standardizing the columns of `df`. In the previous TP we used the method `StandardScaler` of `sklearn.preprocessing`. Notice that you can also simply compute the mean of `df` with `df.mean()` and the standard deviation with `df.std()`, then in one line of code get `df_scaled` by performing algebraic operations on dataframes!\n",
    "* We actually doe NOT want to standardize the <b>last column</b> (the class label). Make sure the last column of  `df_scaled` has the ORIGINAL label values +1 or -1.\n",
    "\n",
    "Then, the question you should answer to complete this section is: what are the mean and standard deviation of the lines and the columns of the `redness` and `elongation` features before and after standardization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Put here your call to the UNIX command \"head\".</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redness,elongation,fruit\r\n",
      "8.429611650485437,1.4032012759326986,1.0\r\n",
      "42.89607843137255,1.7032009898154288,1.0\r\n",
      "56.354066985645936,1.5508105645577395,1.0\r\n",
      "-10.528846153846153,1.7773426521360935,1.0\r\n",
      "-17.131386861313867,2.047174441534352,1.0\r\n",
      "36.041666666666664,1.4139561143744013,1.0\r\n",
      "34.744932432432435,1.2379057682280559,1.0\r\n",
      "1.8179190751445087,1.0839275628229141,1.0\r\n",
      "3.34106529209622,1.0972000640347488,1.0\r\n"
     ]
    }
   ],
   "source": [
    "!head ./mini-dataset/RE_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Read file RE_data.csv as a dataframe and call it \"df\".</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redness</th>\n",
       "      <th>elongation</th>\n",
       "      <th>fruit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.429612</td>\n",
       "      <td>1.403201</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.896078</td>\n",
       "      <td>1.703201</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.354067</td>\n",
       "      <td>1.550811</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.528846</td>\n",
       "      <td>1.777343</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.131387</td>\n",
       "      <td>2.047174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     redness  elongation  fruit\n",
       "0   8.429612    1.403201    1.0\n",
       "1  42.896078    1.703201    1.0\n",
       "2  56.354067    1.550811    1.0\n",
       "3 -10.528846    1.777343    1.0\n",
       "4 -17.131387    2.047174    1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir,'RE_data.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Show descriptive statistics with the method \"describe\".</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redness</th>\n",
       "      <th>elongation</th>\n",
       "      <th>fruit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.863426</td>\n",
       "      <td>1.468878</td>\n",
       "      <td>0.356415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.805386</td>\n",
       "      <td>0.521078</td>\n",
       "      <td>0.935280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-47.045455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.895620</td>\n",
       "      <td>1.161664</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.380952</td>\n",
       "      <td>1.300111</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.848108</td>\n",
       "      <td>1.598103</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.364865</td>\n",
       "      <td>5.231697</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          redness  elongation       fruit\n",
       "count  491.000000  491.000000  491.000000\n",
       "mean    17.863426    1.468878    0.356415\n",
       "std     21.805386    0.521078    0.935280\n",
       "min    -47.045455    1.000000   -1.000000\n",
       "25%      3.895620    1.161664   -1.000000\n",
       "50%     14.380952    1.300111    1.000000\n",
       "75%     33.848108    1.598103    1.000000\n",
       "max    100.364865    5.231697    1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Show the heat map of \"df\".</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a9da05630>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df, annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Standardize the columns of \"df\", EXCEPT THE LAST ONE.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redness</th>\n",
       "      <th>elongation</th>\n",
       "      <th>fruit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.910000e+02</td>\n",
       "      <td>4.910000e+02</td>\n",
       "      <td>491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.085350e-16</td>\n",
       "      <td>-8.266752e-16</td>\n",
       "      <td>0.356415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.935280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.976736e+00</td>\n",
       "      <td>-8.998221e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.405668e-01</td>\n",
       "      <td>-5.895726e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.597070e-01</td>\n",
       "      <td>-3.238798e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.330612e-01</td>\n",
       "      <td>2.479972e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.783535e+00</td>\n",
       "      <td>7.221221e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            redness    elongation       fruit\n",
       "count  4.910000e+02  4.910000e+02  491.000000\n",
       "mean  -1.085350e-16 -8.266752e-16    0.356415\n",
       "std    1.000000e+00  1.000000e+00    0.935280\n",
       "min   -2.976736e+00 -8.998221e-01   -1.000000\n",
       "25%   -6.405668e-01 -5.895726e-01   -1.000000\n",
       "50%   -1.597070e-01 -3.238798e-01    1.000000\n",
       "75%    7.330612e-01  2.479972e-01    1.000000\n",
       "max    3.783535e+00  7.221221e+00    1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "df_scaled = (df - df.mean())/df.std()\n",
    "df_scaled.iloc[:,-1] = df.iloc[:,-1]\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Your final answers to question 1. </b> What are the mean and standard deviation of the lines and the columns of the `redness` and `elongation` features before and after standardization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.658768\n",
      "39.6587674942419\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background:#00FF00\">CORRECT<br>:-)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = 1\n",
    "score = 0\n",
    "# Put your answers to question 1 here\n",
    "redness_mean_before, elongation_mean_before, label_mean_before = 17.863426, 1.468878, 0.356415\n",
    "redness_std_before, elongation_std_before, label_std_before = 21.805386, 0.521078, 0.935280\n",
    "redness_mean_after, elongation_mean_after, label_mean_after = -1.085350e-16, -8.266752e-16, 0.356415\n",
    "redness_std_after, elongation_std_after, label_std_after = 1.000000e+00, 1.000000e+00, 0.935280\n",
    "\n",
    "# This is the checker code, keep it\n",
    "answer = redness_mean_before+elongation_mean_before+label_mean_before\n",
    "answer += redness_std_before+elongation_std_before+label_std_before\n",
    "answer -= redness_mean_after+elongation_mean_after+label_mean_after\n",
    "answer -= redness_std_after+elongation_std_after+label_std_after\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Write a function to standardize data\n",
    "It is often useful to `standardize` the columns of the data matrix to put all values in a similar scale, so to facilitate re-using this operation, write a function that takes as input a data frame `df` containing a dataset and returns a dataframe `df_scaled` with the columns standardized <b>EXCEPT THE TARGET VALUES</b> of the last column (use your answers to the previous section). Use this template for your code:\n",
    "\n",
    "    def standardize_df(df):\n",
    "    '''Standardize all the columns except the last one (target values).'''\n",
    "    # YOUR CODE HERE\n",
    "    return df_scaled\n",
    "    \n",
    "Test your function with the same dataframe as in the previous questions and use the methods `head` and `describe` to verify that all the columns are standardized, except the last one. Notice that, due to machine precision, you may not get exactly mean=0 and std=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data_df[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redness</th>\n",
       "      <th>elongation</th>\n",
       "      <th>fruit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.432637</td>\n",
       "      <td>-0.126039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.148003</td>\n",
       "      <td>0.449690</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.765190</td>\n",
       "      <td>0.157238</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.302076</td>\n",
       "      <td>0.591975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.604870</td>\n",
       "      <td>1.109809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    redness  elongation  fruit\n",
       "0 -0.432637   -0.126039    1.0\n",
       "1  1.148003    0.449690    1.0\n",
       "2  1.765190    0.157238    1.0\n",
       "3 -1.302076    0.591975    1.0\n",
       "4 -1.604870    1.109809    1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace by your own code:\n",
    "def standardize_df(df):\n",
    "    '''Standardize all the columns except the last one (target values).'''\n",
    "    df_scaled = (df - df.mean())/df.std()\n",
    "    df_scaled.iloc[:,-1] = df.iloc[:,-1] \n",
    "    return df_scaled\n",
    "\n",
    "df_scaled2 = standardize_df(df)\n",
    "df_scaled2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redness</th>\n",
       "      <th>elongation</th>\n",
       "      <th>fruit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.910000e+02</td>\n",
       "      <td>4.910000e+02</td>\n",
       "      <td>491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.085350e-16</td>\n",
       "      <td>-8.266752e-16</td>\n",
       "      <td>0.356415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.935280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.976736e+00</td>\n",
       "      <td>-8.998221e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.405668e-01</td>\n",
       "      <td>-5.895726e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.597070e-01</td>\n",
       "      <td>-3.238798e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.330612e-01</td>\n",
       "      <td>2.479972e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.783535e+00</td>\n",
       "      <td>7.221221e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            redness    elongation       fruit\n",
       "count  4.910000e+02  4.910000e+02  491.000000\n",
       "mean  -1.085350e-16 -8.266752e-16    0.356415\n",
       "std    1.000000e+00  1.000000e+00    0.935280\n",
       "min   -2.976736e+00 -8.998221e-01   -1.000000\n",
       "25%   -6.405668e-01 -5.895726e-01   -1.000000\n",
       "50%   -1.597070e-01 -3.238798e-01    1.000000\n",
       "75%    7.330612e-01  2.479972e-01    1.000000\n",
       "max    3.783535e+00  7.221221e+00    1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background:#00FF00\">CORRECT<br>:-)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is the checker code, keep it\n",
    "question = 2\n",
    "answer = (df_scaled == df_scaled2).all().all()\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Select the best representation\n",
    "We are now going to loop over all datasets and compare the performance of our baseline method (one nearest neighbor classifier) with and without variable scaling. \n",
    "\n",
    "First you will perform these steps (with some help):\n",
    "* Import `KNeighborsClassifier` from the scikit-learn library (`sklearn`) and instanciate a one nearest neighbor classifier that you will call `sklearn_model`. Also import the `balanced_accuracy_score` and name it `sklearn_metric`.\n",
    "* Call `df_cross_validate(df, sklearn_model, sklearn_metric)` and collect the results, then print the training and test performance and their error bars. <b>Tip:</b> look at the bottom of the code using `??df_cross_validate` to get an idea on how to print the results. \n",
    "* Create:\n",
    " * a list containing all the dataset dataframes and call it `all_data_df`\n",
    " * a list containg all the dataset names and call it `data_name`. \n",
    "* Run the function `systematic_data_experiment(data_name, all_scaled_data_df, sklearn_model, sklearn_metric)` and display the results.\n",
    "* <b>Create a list</b> containing all the SCALED datasets (variables standardized) and call it `all_scaled_data_df`.\n",
    "* Run again `systematic_data_experiment` on `all_scaled_data_df` and display the results.\n",
    "* Fuse the results of the two previous question by creating a dataframe called `joint_results`. Assign `result_scaling.perf_te` to a column called `'SCALED'` and `result_noscaling.perf_te` to a column called `'NOT SCALED'`. Display the results.\n",
    "* Visualize `joint_results` with a histogram. Check <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html\">this documentation</a>.\n",
    "\n",
    "Then the questions you should answer are:\n",
    "* Does re-scaling variables always help?\n",
    "* Is which case does it help most?\n",
    "\n",
    "Try to reason why this might be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Make necessary changes; USE THE DOCUMENTATION OF SCIKIT LEARN (do not copy on your neighbor).</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier # Replace that by nearest neighbors\n",
    "from sklearn.metrics import balanced_accuracy_score as sklearn_metric # Replace that by balanced accuracy \n",
    "sklearn_model = KNeighborsClassifier(n_neighbors=1) # Replace by ONE nearest neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Collect the results of df_cross_validate(df, sklearn_model, sklearn_metric).</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 66 199 123 222 447 248  34 444 268 157 216 300 200  72 210 273 295 121\n",
      " 481 356 170  64 408 345 379 471 245 234 244 485 110 116 139 117 369 109\n",
      " 285 415 130 183 224 134 205 469 218 156 184 262 264  31 317 384  90 186\n",
      " 103  70 219 148  65 231 483 486 460 220  99 312 318 131 145  55 487 383\n",
      " 399 164 326  33 327 393 160 135 404  28  86  41 190 350 394 232 452 260\n",
      " 361 201 348 178  32 149 132 387  50  27 243 453 267 225  13 266 414 175\n",
      " 358 405 420 426 194 122 474 198 334 339 177 343 390 381 140 171 429 127\n",
      " 457 187  47  56 281 337 241 322 169 275 107 402  40 324 247 372 407 255\n",
      " 376 256 221 228 165 303 385  53 370 309 310 359 308 305 314 437 421 302\n",
      " 472 162 163 212 435 108 100 467 464 325 150   9  60   7 141 449  71  44\n",
      " 144 151 375 242 397 277 235 455 425 101 353 386 193  49  62 456 138  63\n",
      "   0 396 389 208 403 195 373 412 323 355  18 276  43 155 176 282  75 223\n",
      " 147  21 368 274 428 283 111  98 126 417 118  52 237 466 297 354 125 448\n",
      " 459 191 490 230 189 382 153 279 197 410 188] TEST: [211 395 236  61 252 203 488  79 409 418 113 479  42 431 129 328  17 278\n",
      " 185  23 296 270 136 320 391 233  12 344 424 167 251 215  26 333 319 439\n",
      "  83 311  51 416  14 341 226   3 364  10 263 433  36   2  88 367  85 261\n",
      " 422 365 461 411 443 265 269 105 360 182  16 146 259  78 475 294 313 154\n",
      " 307 213 489 438 366 115 470  69 196 214 304 316  77 480 340  45  59 258\n",
      " 137 271 458 419  22   8 239  29  89 280 336   5  74 468 181   1 207 152\n",
      " 378  48 249 342 454 332 380 204 347 446 445 292 392 209 272 291 363 440\n",
      "  95  11  76 180 217 287 142 463  20 179 143 406 102 159  82  15 119  91\n",
      " 330 329 374 246 462 284 451 120 166 301  97 289 114  93  38 192   4  84\n",
      " 362   6 371  37 106  39  24 346  57 413 202 335 398 124  19 432 250 206\n",
      " 478 442 436 401 482 377 174 484 112 423 357 227  96 315  54  68 161  73\n",
      "  46 158 465 400 172 128 477 257 434 288 427 388 351 168 306  94  81 349\n",
      " 254  58 473  67  80 240 450  30 321 286 430 331  92 293 133  35 173 476\n",
      " 299 238  25 338 352 298 253 290 229  87 104 441]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.6497384976881679\n",
      "TRAIN: [109  89 320 268  42 278 362  90 344 185 255   4  74  87 222 230  86 370\n",
      " 420 163 130 305 287 137 319 189 176 188 108 190  55 264 284 306 485 192\n",
      " 138 217 437   0 455 234 289 338 186 213 141 114 117 285  28  51  32 131\n",
      " 435 387 340 249  24 380 274 216 167 341 379 206 474 371 271 425 175 450\n",
      " 103 383 394 267  21  76 229 447 292 123  94  82 151 452 168 378  70 470\n",
      " 296 184 199 251 334 314 479 374 232 172  68 191  13 449 361 164 139 414\n",
      " 281 211 282 475 466 212 233  18 155 242   9 321 406 324 312 395  56 107\n",
      "  53  44 193  29 396  31 327 273 389 486 388  39 469 125  78 147 152 231\n",
      " 203 210 343 384  17 166  61 261 252 412 105  91 355 463 311 263 286 113\n",
      " 482 180  97 149 333 354 290 436 260 461 256 489 369 423 132 326  88 410\n",
      " 201  69 154 427 265  12 471 376 181 401 484  72 483   1 143  54 386 359\n",
      "  99 115 245  36 405 328 208 182  59 243 342 391 241  26  34 418 300  73\n",
      " 358 335 315  10 197 269 360 468 460 417  79 304 322 409 363 476 247 400\n",
      " 332 236 473 459 331 194 443  25 438  96 224] TEST: [472  38 111  71 451 173 101 244 135 313 349  45 404 140 129 480  67 464\n",
      " 170 488 144  85 272 177   6 119 254 262   8 275 440  75 385 487 302  57\n",
      " 442 116 156  50 218 259 415 308 407 200  83  64 215 196  27 118 214 202\n",
      "  30  58  20  66 122 393 235 456 337 367  95 228 399 142 434 299 209 207\n",
      " 204  92 346 226 330 478 288 276 169 121 403 124 429 318 270 198  33 372\n",
      "   7 157 428  80 381 307 295 345 348 110  19  52 301 416 128 165 431 112\n",
      " 159  43 279 238 309   5 161 183 351 146 365 246  62 377 162 465 102 136\n",
      " 424 174 356  14 153 445  98 253 477 277   2 422 490 239 298 205 454 283\n",
      " 329 258 481 280 248  41  46 223  48  47 316  77 266 467  65 323  49 240\n",
      " 433 350 100 179 225 227 336 368 448 148 195 150 382 250 366 353 453 402\n",
      " 408 432 364 397 458 257 104  84 352 187 398 219 357 178  63 297 291 106\n",
      " 134 339 390  16 439 120  15 160 158 293 220 347 462 441 375  11 145  60\n",
      " 430 127  23 317 444 413 426  37 126  81 411 221 303 457  35 310 446   3\n",
      "  40  22  93 133 171 419 294 421 325 373 237 392]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.644091563708027\n",
      "TRAIN: [143 291 433 269 387  93 415 357 426 467 208  71 278 429 275 298 449 115\n",
      " 210 340 262 232 230 167 103 315  16  46 332  79  59 255 192 141 265 127\n",
      "   9  86  36   5 402 464  89  25 465 414 469 393 454 264 183  28 112 382\n",
      " 356 285 241 317 270  87 128 352 250   1 292  95  17 397 358 209 248 424\n",
      " 373 247 237 198 300  37 441 159 174 188 470  11 181 436  68 125 240 354\n",
      "  82 420 110  98 343 314 185 126 488 398  62 299 131 419 287 173 272 475\n",
      " 301 178 345 442 122 463 453  77  50 175 109 410  61 395 348 479 279 229\n",
      " 316  47 207 485 437  54 133  40 347 289 431  66 490 417  15 256 239 191\n",
      "  58 176 336 274  51 263 313 338  19 253 214 443 359 389 477 319 171   2\n",
      " 439 362  41 331 216 321  42 341 225 246  83 430  13 139 259  69 142  20\n",
      " 392 187 455 444 218 364 428  57 326 104 144 231 123 213  14  12 160  49\n",
      " 138 461 324 234  76 163  55 384   0 177 186 412 297 224 273   4 458 401\n",
      " 335  45 446  18 211 124 421 375 113  65 471  27 457  38 276 303 233 281\n",
      " 391 432  97 283 427 194 245 355 388 130 342] TEST: [413 310  44 179 267 219 102 383  94 376 223  29 169 330  26  80 100 363\n",
      " 118 114 106 438 304 153 372 484 405 325 328  39 137 180 344 480 440  10\n",
      " 425 407 184 396 252 190 290 329 386 353  21 452 111 202 129 311 416 266\n",
      " 327 409 260 378 156 400 361 150 238 226  33  30 293 379 377 203 196 371\n",
      " 309 135  84 242  32 235 280 222   7 487  34 195 166 170 459 288 204 155\n",
      " 158 249 312 221 227 200  31 119 205  90  92 206 284 450 117 365  99 286\n",
      " 445 472   3 217 236 322 145 295  52 243 193 212 381 339 462 244 154 151\n",
      " 121 261 108 404 161 466  22  73 199 434 474 367 334 165 189  75 349 164\n",
      " 302 215 258 468 460 390 228  23  60 296 337 157 483 394 333  24 162 268\n",
      " 399 101 254 403 346 306 374 380 451 146 271 489 120  63 478 418 168  35\n",
      " 435 351 447 294 308 307  85  72  48 105   6 320 323 149 152 107 408  96\n",
      "  56 318  53 134 411 116  64 197  74 385 406 476 473  91 422 368 370 220\n",
      " 448 482  78 350  67 277 257 282   8  43 132 182 486 148 147 423  81 366\n",
      " 369 456 251 305 360  70 140 136 201  88 481 172]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.6334040779201091\n",
      "TRAIN: [231 196 191 297 317 138 312  16 379 439 319 122 446 295 318 381 339 188\n",
      " 401 250  92 341 344 337 410  49 109 244 253 333 413  82 158 175 430 230\n",
      " 170   8 226 462 399  38 426 259 421 126 441 293 389 239 168 124 260 398\n",
      " 252 177 482 289  11 271 217 205 172 388 422  74 402 249 305 140 382 412\n",
      " 459 400 419 392 342 313 447  18 207 213 156 187 327 475 211 472 245 284\n",
      " 460 141 434 144 438 210 281  99  91 335 102  20 480 268 157 393 309 148\n",
      "  48 111 316 100 233 101 222 179 142 357 166 454 251 131 278 287 353 395\n",
      " 283 364  77 265 414 190 225  41 355 181 135 348  59 107 464 224  23 372\n",
      " 275 234 167 134 433  70 154 440 356 308 461 451 431   5  15 325  81 304\n",
      " 456 367 173 237   7  84  54 132 276 194 369  95 163 139 243 155  27 121\n",
      "  17  63  40 241 436  42 185 174 292 377 232 429 291  44 332  14   0 228\n",
      " 212 352 246 169 214 444 235 467  73 294 409 380 458 366  62 487 425 206\n",
      "  85 437 417 258 476 270   1 296 415 216 435  80 195 483 125  61  58 274\n",
      " 489  98 280 238  57 468  39 103  10 117 311] TEST: [ 53  72 219 450 302  94 118 354 152 390 485 161 180 153  25 197 129 360\n",
      " 455 428 113  22  24 223 267 182 478 420 346 120 371 184 269  69  93 387\n",
      " 114 368 261 391 326 416   3 378 463 418  43 240 215 136 404 361 408 199\n",
      "   6 477 351 248 486 448 432 299 405  45 303  67 149 469 277 330  88 176\n",
      " 484 340 242 256 397 133  37 255 406 328 479 474 481 227  47 365 322 137\n",
      " 298  60 236 290 171 370 104 443 385  83 229 320 331  28 321 470 466 220\n",
      " 465 123 151 164 349 488  12  30 112 193 347  75 363 115 145 490  87 257\n",
      " 323  26 300  46 427 165  21  34  13 119 202  97 279 128 350 282 218 359\n",
      " 442 376  32  66  76 116 201 203 159  35 386   2  71  78 108   4  50 373\n",
      " 329 453 457 403  79  68 301 288 343 473 143 247 358 383 306 150 307 336\n",
      " 471  29 384 178 424 262 324 110 334  36 396   9  52 263 192 160 338  86\n",
      "  64 407 200 209  89 315 189 254 162  90 411 362 264 146 345  55  56 445\n",
      " 394  65 208 204 266 147 449 105 183  31 221 186 272 198  96 273 423 106\n",
      " 452 286 285  19 310  51 375 374 314  33 130 127]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.6330629879481543\n",
      "TRAIN: [ 14 453 365 195 308 158 356 386 330 180 368 312  16  75 402 176 225 151\n",
      " 344 351 162 112  84 230 461 443 435 227 221 217 421 181 325 138 194 242\n",
      " 319  29 284 289  37  26 404 166 382 202  28 347 218 384 263 267 130 420\n",
      " 445  22 231  67 470 381 302 170 219  80 209  95 440 203 329 484 192 148\n",
      " 450 189 451 136 141 331  87 282 198 403 208 476  82 395 276  56 434 145\n",
      "  18 335 387 121 200 196 486 406 324 167 104 489 360 224 338 448 253 358\n",
      "  58 416 462  15 333 157  19 352 304 313 464 254 205 204 236  49  89  41\n",
      " 127 182 322 438 129 485 107  21 258 481   9 214 165 316  24 216 159 473\n",
      "  61  32 311 125  66 361 455  27 106 315 457 139 463 126 260 399 273  86\n",
      " 270 259 380 266 417 396 285 226 370   4 334 251 410  74 186   2 357 369\n",
      "  35 433  45 269 250 355  83 117 132  40   8 469 174 364 426 201 349 465\n",
      " 212 296  44 234 378 320 135 441 244 277 385 235 197 447 183 474 375 411\n",
      " 110 398 193   1 419 327 179 275 292  92  38 393 389 156  59 229 339 114\n",
      " 413  10  33 146   7  11 323 280  43 238 154] TEST: [ 39  42   5 305 105 168 246 287 407 490 262 286 213 173  79 122 372 471\n",
      " 328  48  12  63  20 150  77 409 294 337 348 303 341 332 295 478  60 321\n",
      " 391 261   3 256  34  51 354 418 480 228 232 153 113  99 444 271 394 243\n",
      "  70 101 326 111 483 340 439  98 239 405 362 309 467  88 257 178 363 377\n",
      " 268 414 264 241 390 116 424  31 459  96 103 428 247 472 383  52 400 423\n",
      "  55 376 342  53 482  17 155 210 240 427  97 207 279 468 422 143  64 436\n",
      " 147  13 187 317 374 299   0 442 300 164 297  62 379 314 272 437 336 188\n",
      " 306 432 171 119 149 318  23  94  36 449  47 248 412 140 120 118 160 415\n",
      "  93 408 175 293 190 454 191 108 388 343 177 142  46 488 446 255 278 290\n",
      " 425  69 367 274 431 206  30 184 392 211  78 233 115 245  91 466 452 346\n",
      " 477 345 288  68 249 123 475 163  25  57 456 460  72 265 223 298 169  90\n",
      "  81 100 350 172 252 144 134  85 487 109 281 283 371 479 458 291 237  50\n",
      " 307 161 199 429 131 124 133 401 366 359 102 215 397  54 430 220  73 222\n",
      "   6 301 137  71 185 128 353 310  65  76 373 152]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.6587205336163117\n",
      "TRAIN: [104  25 172 405  90 271 348 467 384  41 277  78 220 334 356 430  14 155\n",
      " 331  68 364 290 130 482 256 372 437  92 238 451  43  88 480 351   1 329\n",
      " 363 419 217  74 116  86 413  18 267 421 254 186  26 189 312 201 265 128\n",
      " 240 297 477 214  59 120 386 168 129 463 317 141 158 178 309  89 237 283\n",
      " 101 433 409 188   9 282 343 404 262 133 324 123 377 222  48 393 219 397\n",
      " 332 415  12 181 375 326 417 466 454  40 197 310 435 315 115 273 118 139\n",
      " 152 143 132 298 198 455 167 173 346 353 485 427 401 471  69 400  55  38\n",
      "  29 169  85 289  57 306 308 156 358 373 226 245 366 395 112 218 147 403\n",
      " 336 111 255  87 359 175  11 117 307  23 345 243 131  15 144 106 292 246\n",
      " 253 450  80 184 355 376 341 392 287 258 150 142 209 125 347 206 432 446\n",
      "  79 252  37 481 191 453 145 204 449 442 314 354 342  67 436 378 459  96\n",
      "  16 457 108  98  73 174 223 487 272 406 484  81 302 229  53 291 279   2\n",
      " 124 242 303 228  31 490  63 444 431 202  19  45 180 192 428 443 399 388\n",
      "  64 182 166  33 370  39  44  17 161 190 320] TEST: [380 390 439 203   3  52 251 127 362 398 381 286 165 394 389  60 418 216\n",
      " 352  42  66 194 149 176 230 270 349 304 434  76 486 474 426 136 472 185\n",
      " 278  36 102 361 225 285 296 476  24 244 440 408  34 473 360 196   0 462\n",
      " 259 468 274 140  47  61 330 280 461  51  65 221 212 382 249  95 371 328\n",
      " 100 207 261  30  27  75 410  83  32  84  50  46 425 210 260 340 234 137\n",
      " 135 489 322 205 313 276 464 109 250 367 385 295 159 391 154 263 488 121\n",
      " 299 456 171 248 294 325  99 195 469   4 305 379 448 422 157 396  77 119\n",
      " 215 113 211 146  54 316 227  62 383 368  70 447 338 357  91  71 164 301\n",
      " 148 187 268 475 339  13 288 264 284  94 153 387 318 114 231  20 199 424\n",
      "  97 122  58 193   6 374 452 460 281 335  28 160 337 365 247 275 369 300\n",
      " 311 110   5 478 411 445 239 321 323 319 232 213 235 407   8   7  82 412\n",
      " 479 107 423 233 200  10 327 170 483 138 293 105 344 266 470  21  49 151\n",
      " 208 134 465  22 441 414 438 236  93 257  72 179 162 224 241 163 269 103\n",
      " 177 183 458 333  35 350 402  56 420 416 429 126]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.7070416129765784\n",
      "TRAIN: [221 411 165 363 367 297 196 439  74 267 182 306  42 224 349 389 336  10\n",
      "  46  59 101 237 298 273  88 374 371 249 341 259  21 319 283 489  57  83\n",
      " 305 445  71 307  60 414 287  41 112 174 365 268 463 157 133   4 152 284\n",
      " 251 156 487 132 204 141 242 257 394  17  52 149 134 308 135   1 475 470\n",
      "  91 138 291 121 229 275  49 124 454 415  23 202 486 338  31 292 117 458\n",
      "  68  84 464 356 384 173 410 340 478 170 443 393 136 449 256  73 317  40\n",
      "  95 254 107 260 320 397 433 372 166 313 235 357 281  75 200  56  53 238\n",
      " 179 129 482 418 219 140 451  61  97 483  77 311  65  26 286 158 111 348\n",
      " 416  34 447 282  35 276  45 150 485 362 113 395 212 122 469 285 299 425\n",
      " 480 220 188 453 426 186 404  96 437 279  48 178 378 104 119 344 369 396\n",
      " 250 490   5 462  43 218 214 161  63 409  38 253 105 223 294 352  13 476\n",
      " 153 407 388 195 125 233 379 213 280 151  39 459 360   7 207 169 423 222\n",
      "  98 326 392 446 381 139 123 322 351  93  81 448 441 339 325 288  33 421\n",
      "  72 488 420  58   9 243  51  85  50  15  37] TEST: [144 109  90 108 189 324  12 146 217 408 184 239 435 270 484  36  11  62\n",
      " 100 255 368  54 327 380 347 472 452 401 203 190 309 205 162 413 272 258\n",
      " 334 399 343  89 199 318  27 234 302  82 303 163 376 278 364 314 115 120\n",
      " 385 128 114   8  24 424 361 473 466 264 390 304 436 245 316   2 289 323\n",
      " 310 375  44 247 225 428 335 180 154 321 197  32 387 130 241 266 300 232\n",
      " 333 438  94 460 417 293 230 345 215  25 332  99 209 457 355 216  69 383\n",
      " 479  70 398 370  87 474 271 444 301 206 377 471 168 465 118 427 131 468\n",
      " 290 240 342 481 191 183 312  79 366 434 403 143 159 337 430  76  67 181\n",
      " 350 261 187 226 145  55 359 400 194 175  80  78  86  28 231 137 116 176\n",
      "  19  29 429   0 126 461 405  14   6 211 442 440 110 330 391 102 192 406\n",
      " 277 295 402 346 455 236 227 358 201  66 252 432 106   3 155 331  47 419\n",
      " 208  20 296 477 265 167 431 274 354 450 244 262  16 103 263 386 127 193\n",
      " 160  30 210 269 315 373 382 172 467 142 171 329 185 412  92 147 177 198\n",
      " 246  18 148  64 353 328 228 248  22 164 422 456]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.5837944364435685\n",
      "TRAIN: [335 245   7 166 282   8 142 209 314  18 454 304 344 121 450 140   4 138\n",
      " 227  33 182 196 414 336 446 385 173 389 313 324 442  93 373 241  47 222\n",
      " 220  49 416 280  54 455 254 481 148  84 413 177 153 342  77  62 388 368\n",
      " 120 488 239  70 306 458 232 436 244 433 249  58 401 398 263 204 308 351\n",
      " 315 185 103  31 139  42 191 403 214  71 441 197 325 466 137  99  66 176\n",
      "  94 346 483 179 186 396 321 201  23 223 320  24   1 478   3 203 422 332\n",
      " 226 349 348  83  53 485 256 202 418  45 340 361 295 242 337 272 168 246\n",
      "  89  34 469 131 134 467 116  52 155 199 362 269 174 439  20 278 125 339\n",
      " 425 381 150 275 395  75  55 143 132 112 463 236 290 238 411 477  85 479\n",
      " 105 288 428 305 111 322 405 200 333  48  87   5 136 301 444 480  41 438\n",
      " 386 384 234 400 145 486 192  17 210  26 113 189 104  27 402 184  64 293\n",
      " 471 279 360  16 190 303 251 474  80 311 377 211 318 420 172 347 380 357\n",
      " 356 283 459 237 152 258 482 129 432  98 159 452 472 161 193   6 456 300\n",
      " 108 298 217 122 127 175 343 215 233 273 274] TEST: [370 451  86 484 440 101 310 390 277 253 490  91 102 157  12  13 118 231\n",
      " 468 371 165 206 443   0 270  40  28 476 213 198 376 123 262 208  76 135\n",
      " 160 464 307  15  30 465  63 240 141  78 312 291 415 268 447 115 393 257\n",
      "  22 219 408 261 353 229 128 475 417 284 287  65 151  59 426 167 286 364\n",
      " 124   2 250 271 289 375  25 334  37  73 328  88 180  95  61 255 296 114\n",
      " 460 359 429 372  72  69 147 341 299 181 473  50 363 156  68  38 407 387\n",
      " 130 264 434 110 169 319  14 194 309  90 266  44 144 107 355 367 230  36\n",
      " 281  67 188 183 409  81  97 421 365  39 374 470  29 366 216 316 489 445\n",
      " 119 326 352 276 358 158 117  74 378 146 235 399 462  82 100 369 207 224\n",
      " 178 109 430  79 267 382  51 292  96  56  46 449 424 248 164 302 435 350\n",
      " 487 294 437 354 391 461 331 453 404 423 394 406 154 221 419  57 252 195\n",
      " 265 163 285 212  21 431 259 106 171 228 345  35 397  10 162 329  60 133\n",
      " 379 383  11 218 170 205 330 338 448 323 260 317 149 247 243  43 126  92\n",
      " 187   9 457 412 410 225 392 327  19 427 297  32]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.6360569999242023\n",
      "TRAIN: [352 109 400  52 383   0 379 355 128  95 170 451 384 105 465 390 318 217\n",
      " 129 487   6  76  14 201 167 372 283 312 305 143 130  46 231 291 290 398\n",
      "  74 449 456  48 454 127   4  64 476 387 253 433 144 397 365  69 280 205\n",
      " 278  45 119 452 467 457 388 274  50 460 282  15 363 334 430 445 316 247\n",
      " 115 155 450 375 351 267 220 104 446 368  24 377 171 416 409 309 121 364\n",
      " 277 122 189 186 407 136 219 405 326 380  86 213 152 399 139 182 153 428\n",
      " 490 179  20 295 382 142  83 192 184 161 113  13 224  32 249 137 488 302\n",
      " 237  44 188  22 328  62 168  65 338 354 134  75  57 185  47 234 116  85\n",
      "  35 329 148 190 124 440 335 191 444 214  11 402 138 243  99 477  16 286\n",
      " 401 194 424 263 229 395 436 180 455 325 276  63 459 244  67 195 287 107\n",
      " 414 296 330 120  82 176 317 484 235  59 406 254 356 208 199 413 386 102\n",
      "  40  79  94  80 308 374 298 426 256 464 108 222 315 158 481  54 212  92\n",
      " 366  70 297 336 486 197 147 394 140 218 198 403  19 203 178 438  21 441\n",
      " 260  34 419  42 333 202 126 458 262 241 232] TEST: [110  31  27 439  55 173 273 471 435 145 425 183 216 311 420 225 154  68\n",
      " 151 255 269 103 230   2 268 106 294 360 396 245 157  61 149  91   9 466\n",
      " 344 270  36 337 207 172 423 206 443  56 462 391 215 159   8  84 141 472\n",
      " 369 359 299 319 461 193 434  87 411 483 381  25 257 175 415 323 442 353\n",
      " 228 266 165  93 164 342 361  96 261 307 474 156  33  58 480 393 239 223\n",
      " 272 404 236 422 227 478 303 304  71  43  66 163 373 279 238 358 271 389\n",
      " 300 349 250 447 376  51 429  26 417 385  30 348 392 421 370  17 101 301\n",
      " 100  90 331 133 470 240 174 310 350  78  97 362   7 293  49 432 132 473\n",
      "  29 322 437 246 233 135 117 252 482 112  41 332 200  38 314 448 275 111\n",
      " 204 289 242 125  89 118 463  73 343 431  53 313 131  23 320 357  39 339\n",
      "  72  18 371   5 251 162 475   1  81 469 259  12  37 166 209 210 150 292\n",
      " 453 169 321 346  28  10 264 378 412 345 479 226  60 265 196  88 324 181\n",
      " 114 306 468 288 485 284  77 327 187 221 248 418 285 146 489 211 367 258\n",
      " 410  98 347 408 281 340 341 123 177 427   3 160]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.6177518380959599\n",
      "TRAIN: [220 464 390  40 134 354 419  75 412 208 326 233 463  92 234 450 196 423\n",
      " 435   5  21 256  50 353 239 292 223 136 480 446 152 430  26  84 297 128\n",
      " 368 194  80 285 331 465 355 337 409 371 442 168 425 413 448  67 145 432\n",
      " 317 175 174 106 328 284 147 393 206 343   2 422  61 105 151 437 335 179\n",
      "  28 185 173  18 125 101 377 470 333 338 261 286  16   6 291 143 322  85\n",
      " 351  33 250 258  98 190 483 482  58  53 138 429 436 374 244 312 224 382\n",
      " 443 214 158 439 118 453 375 221 341 169 117  95 130 228 154 210  81 296\n",
      " 452 180 176 213 186 356 104 212  37 398 243  51 115 162  45 475  25 230\n",
      " 254 197 370 181 141  91 157 198 489  56 339 268 303  71 403  32 201 406\n",
      " 202 434 289 188 301 342 431 211 187 306  68  99  41  77 226  47 140 438\n",
      " 209 421 189 129 415  66 366 159  36 222  22 401 444 350 440 447 400 148\n",
      " 441 247 142 487 299 486 426  39 121  19 167 372 149 165   7 137  89 270\n",
      "  55 242 304 124 334  15 265 217  27 273  78 445 485 380 277 237  17 428\n",
      " 235 469  63 249 126 314 218 360 133  76 323] TEST: [139 405 156 113 123 192  64 279 325 283  82 455 399  73 386 302 300 112\n",
      " 108 191 345 170 459  38 255 454 269 462   1  49 461 216 252 215 310 397\n",
      " 225 253  62 298 309 391 103  29 241 263 282 132 481 479  11  79 347   9\n",
      " 163 416 315 318 178 348  14 203 473 476 160 119 384 276 329 111 365 246\n",
      " 293 287  70 414 274 164  57 357 418 116  94 472 407 396 264 172 155 327\n",
      " 161  65 336 245 195 204 248 207 278 324 467 232 153 471 320 346 294 308\n",
      "  59  52 183 146  72 219 364 352 227 361  74 319 474 100 150  34 231 358\n",
      " 177 229 290 392 340  97 171 305 262 460 451 378 200  93 363 311 109 379\n",
      " 122 376 199 387  60  43 275  12  83   8 410  24 193 394 131  88 251 184\n",
      " 344 373 466  30 267 271 120 488 484 166 144  48 369 107  87 280 359 257\n",
      "   4  10  96 313 332 383 182 457 135 381 110 260  20 395  86  31 362  42\n",
      " 456 427  54 321 385 349  13   3 288 205  44 272 240 102 408 411  69 490\n",
      " 266 389 402  35 420 114 238 433 127 417  46 468 449 307 330 477 259 478\n",
      "  90 281 295 236 367 458   0 424 316  23 404 388]\n",
      "TRAINING PERFORMANCE METRIC 1.0\n",
      "TEST PERFORMANCE METRIC: 0.6583794436443569\n",
      "*** AVERAGE TRAINING BALANCED_ACCURACY_SCORE +- STD: 1.00 +- 0.00 ***\n",
      "*** AVERAGE TEST BALANCED_ACCURACY_SCORE +- STD: 0.64 +- 0.03 ***\n",
      "(1.0, 0.0, 0.6422041991965435, 0.03001175793679763)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE TRAINING BALANCED_ACCURACY_SCORE +- STD: 0.64 +- 0.03\n",
      "AVERAGE TEST BALANCED_ACCURACY_SCORE +- STD: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "print(df_cross_validate(df, sklearn_model, sklearn_metric,verbose = True))\n",
    "\n",
    "\n",
    "p_te, s_te, p_tr, s_tr  = df_cross_validate(df, sklearn_model, sklearn_metric)\n",
    "\n",
    "metric_name = sklearn_metric.__name__.upper()\n",
    "print(\"AVERAGE TRAINING {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_tr, s_tr))\n",
    "print(\"AVERAGE TEST {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_te, s_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO SCALING\n",
      "KNEIGHBORSCLASSIFIER\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow0_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow0_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow0_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow0_col3 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow1_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow1_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow1_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow1_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow2_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow2_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow2_col2 {\n",
       "            background-color:  #deebf7;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow2_col3 {\n",
       "            background-color:  #85bcdc;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow3_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow3_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow3_col2 {\n",
       "            background-color:  #75b4d8;\n",
       "            color:  #000000;\n",
       "        }    #T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow3_col3 {\n",
       "            background-color:  #4191c6;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25e\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >perf_tr</th>        <th class=\"col_heading level0 col1\" >std_tr</th>        <th class=\"col_heading level0 col2\" >perf_te</th>        <th class=\"col_heading level0 col3\" >std_te</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25elevel0_row0\" class=\"row_heading level0 row0\" >CROP</th>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow0_col2\" class=\"data row0 col2\" >0.747946</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow0_col3\" class=\"data row0 col3\" >0.0334551</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25elevel0_row1\" class=\"row_heading level0 row1\" >CS</th>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow1_col1\" class=\"data row1 col1\" >0</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow1_col2\" class=\"data row1 col2\" >0.546047</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow1_col3\" class=\"data row1 col3\" >0.0241897</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25elevel0_row2\" class=\"row_heading level0 row2\" >RAW</th>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow2_col0\" class=\"data row2 col0\" >1</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow2_col2\" class=\"data row2 col2\" >0.571887</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow2_col3\" class=\"data row2 col3\" >0.0282349</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25elevel0_row3\" class=\"row_heading level0 row3\" >RE</th>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow3_col0\" class=\"data row3 col0\" >1</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow3_col1\" class=\"data row3 col1\" >0</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow3_col2\" class=\"data row3 col2\" >0.642204</td>\n",
       "                        <td id=\"T_b6d5b0c6_4408_11ea_a36b_d89ef318e25erow3_col3\" class=\"data row3 col3\" >0.0300118</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6a9d979668>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We give you this code, read it and try to understand it\n",
    "data_name = [os.path.basename(file)[:-9] for file in data_list]\n",
    "all_data_df = [pd.read_csv(file) for file in data_list]\n",
    "print('NO SCALING')\n",
    "result_noscaling = systematic_data_experiment(data_name, all_data_df, sklearn_model, sklearn_metric)\n",
    "result_noscaling.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe by comparing the accuracy on training data and on test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Compute all_scaled_data_df in a one-line formula. Imitate the code in the previous cell.</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_scaled_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9c14816da937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_scaled_data_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_scaled_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "len(all_scaled_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_scaled_data_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH SCALING\n",
      "KNEIGHBORSCLASSIFIER\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow0_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow0_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow0_col2 {\n",
       "            background-color:  #3888c1;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow0_col3 {\n",
       "            background-color:  #c9ddf0;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow1_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow1_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow1_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow1_col3 {\n",
       "            background-color:  #e3eef8;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow2_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow2_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow2_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow2_col3 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow3_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow3_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow3_col2 {\n",
       "            background-color:  #c4daee;\n",
       "            color:  #000000;\n",
       "        }    #T_ec0f6566_4408_11ea_a36b_d89ef318e25erow3_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25e\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >perf_tr</th>        <th class=\"col_heading level0 col1\" >std_tr</th>        <th class=\"col_heading level0 col2\" >perf_te</th>        <th class=\"col_heading level0 col3\" >std_te</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25elevel0_row0\" class=\"row_heading level0 row0\" >CROP</th>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow0_col2\" class=\"data row0 col2\" >0.71234</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow0_col3\" class=\"data row0 col3\" >0.0244602</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25elevel0_row1\" class=\"row_heading level0 row1\" >CS</th>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow1_col1\" class=\"data row1 col1\" >0</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow1_col2\" class=\"data row1 col2\" >0.792288</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow1_col3\" class=\"data row1 col3\" >0.0221641</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25elevel0_row2\" class=\"row_heading level0 row2\" >RAW</th>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow2_col0\" class=\"data row2 col0\" >1</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow2_col2\" class=\"data row2 col2\" >0.554434</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow2_col3\" class=\"data row2 col3\" >0.0375432</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25elevel0_row3\" class=\"row_heading level0 row3\" >RE</th>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow3_col0\" class=\"data row3 col0\" >1</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow3_col1\" class=\"data row3 col1\" >0</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow3_col2\" class=\"data row3 col2\" >0.61544</td>\n",
       "                        <td id=\"T_ec0f6566_4408_11ea_a36b_d89ef318e25erow3_col3\" class=\"data row3 col3\" >0.0204092</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6a97edcf60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scaled_data_df = [standardize_df(i) for i in all_data_df] \n",
    "\n",
    "print('WITH SCALING')\n",
    "result_scaling = systematic_data_experiment(data_name, all_scaled_data_df, sklearn_model, sklearn_metric)\n",
    "result_scaling.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCALED</th>\n",
       "      <th>NOT SCALED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CROP</th>\n",
       "      <td>0.712340</td>\n",
       "      <td>0.747946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS</th>\n",
       "      <td>0.792288</td>\n",
       "      <td>0.546047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAW</th>\n",
       "      <td>0.554434</td>\n",
       "      <td>0.571887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE</th>\n",
       "      <td>0.615440</td>\n",
       "      <td>0.642204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SCALED  NOT SCALED\n",
       "CROP  0.712340    0.747946\n",
       "CS    0.792288    0.546047\n",
       "RAW   0.554434    0.571887\n",
       "RE    0.615440    0.642204"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how to collect the test results in a single dataframe\n",
    "joint_results = pd.DataFrame()\n",
    "joint_results['SCALED'] = result_scaling.perf_te\n",
    "joint_results['NOT SCALED'] = result_noscaling.perf_te\n",
    "joint_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Put here the code to plot \"joint_results\" as a bar graph. Check the <a href=\"Check https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html\"> documentation</a></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'balanced_accuracy_score')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEVCAYAAAAYZ2nCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VfW1//F3BkGZBEIUjThdZTlUtKhVa9WqFRm0WocqiqjodWjFuU5t1epFvXVotVKhFhUBUetQUHCsXqfHeyk/wZmFigoCSkQQkDHJ+f2xN+EQAjlf3GdKPq/nyZNzvmfvfVZ24Kzs/R1WSSqVQkREJERpvgMQEZHio+QhIiLBlDxERCSYkoeIiART8hARkWBKHiIiEkzJQ0REgil5iIhIMCUPEREJpuQhIiLByvMdQIJaA/sCc4HaPMciIlIsyoCtgH8DKzLdqTklj32B1/IdhIhIkToIeD3TjZtT8pgLsGDBd9TVFfZijxUV7Zg/f0m+w2g2dD6To3OZrGI4n6WlJXTq1Bbiz9BMNafkUQtQV5cq+OQBFEWMxUTnMzk6l8kqovMZdLtfHeYiIhJMyUNERIIpeYiISLCc9XmYWXdgJFABzAcGuvtHDbbZArgf6Aa0Al4CLnT3mlzFKSJNq62tYcGCampqVuY7lII2b14pdXV1+Q4DgPLyVnTqVElZWTIf+7nsMB8GDHX30WY2ABgOHNZgm2uAD929n5ltQjRs7Djg0RzGKSJNWLCgmk03bUPbtl0pKSnJdzgFq7y8lJqa/CePVCrFd98tYsGCarp02SqRY+bktlV8RdETGBs3jQV6mlllg01TQHszKyWa9NcKmJ2LGEUkczU1K2nbtoMSR5EoKSmhbdsOiV4p5urKoxsw291rAdy91szmxO3VadvdCDxONN64LXC3u78R8kYVFe2SiTjLKivb5zuEZkXnMzmZnMt580rZZJOyHERT/MrLC6drubS0NLH/K4U2z+NE4B3gcKA98IyZneDuj2V6gPnzlxT8uOrKyvZUVy/OdxjNhs5ncjI9l3V1dQVxO6bQFcptq9Xq6urW+f2WlpZs1B/duUoes4AqMyuLrzrKgK3j9nSDgUHuXgd8a2bjgEOBjJOHFLb2HTZj09bJ/rNbuUpLmeVbNn6vAMtX1LB40bKMtn3ppRcZNeo+UilYuXIF3bvvwvXXD6GmpoYHHvg7L774POXl5aRSdey//4Gcf/5gysujmJ944h/cccd/c//9Y9h5Z6s/5gUXnEP//qdx4IEHrfVeQ4Zcz+TJk9h88471baefPohDD/1Z/WsdO3Zk2bJldOrUmWOOOY7evfslcEYKR06Sh7vPM7OpQH9gdPx9irtXN9j0U6A3MMnMWgE/A57IRYySG5u2Lufoy8Ylesynbj8m0eNJuGz8XiH63WZyTfn1119zxx23MGLEaLbcsiupVIqPP54OwE03/YEVK5Zz332jaNOmLTU1NUyYMJ6VK1fWJ48JE8az9977MmHCeC6++DcZxTZgwOkcf/xJG3ytvLyUDz/8kGuvvZqFCxdw8skDMjp2McjlzbjzgMFmNp3oCuM8ADObaGb7xNtcDBxkZu8CU4HpwL05jFFEitA333xNWVl5/ZVASUkJO+9szJo1k1dffZkrr/w9bdq0BaC8vJxjjjmONm3aAPDJJx+zcOECrr76Wl588TlWrkx2+PHOOxsXXXQ5Y8Y8SCpV2LfUQ+Ssz8PdpwH7NdLeN+3xJ8ARuYpJRJqHnXbqzm677c7xx/fjhz/cmx499uLII/syfbqzzTbb0qFDh/Xu+/TT4+jT5yi6dt2KnXbqzmuvvcLhhzf9MTR69EieemrN1dZvf3vdWre80u222w9YsOAbFi5cQKdOncN/wAJUaB3mIiLBSktLufnm25kx42OmTHmL1177Hx56aBSDB1+ywf1WrVrFCy88y/Dh9wPQt+/RTJgwPqPksaHbVutqPlccqyl5iEizseOOO7Hjjjtx/PG/ZMCAE5k7dw5ffDGTRYsWNXr18frrr7B06XdcdNH5QDQaacGCb/jqqy/ZcsuuicX14Ycf0KlTZzp27JTYMfOtcAYgi4hspOrqebz33jv1z+fN+4qFCxfwox/tz4EHHsytt97E0qXfAVBbW8ujj45l6dKlTJgwnksuuYLHHnuKxx57iieemECfPkfxzDNPJxbbxx9/xF133c6ppw5sVpMqdeUhIt/b8hU1WRn1tnxFZsva1dbWMmLEcL78ci6tW29KKlXH2WefT/fuu/C73/2B++77G4MGncYmm5STSqXYf/8DWbToW6ZOfYvrrhuy1rF69erDTTf9gdNPPwuAm266nlatWte/fuutdwLr9nkce+xxHHvsCWu9tmLFcjp27MSAAWfQp89R3+tcFJqSZtT7vz3wqSYJFrbKyvZZGarbUs9n0jL9t/nll5/Ttet2OYiouBXaJMHGfm9pkwR3AD7L9Fi6bSUiIsGUPEREJJj6PPKgrmZl4gv51axcwYJvVVtBRHJDySMPSstbMWPI8Ykec8ffPg4oeYhIbui2lYiIBFPyEBGRYLptJSLfW6fNW1GeNhciKerLK1xKHiLyvZW3ap14Px5k3pd3wglHs9lmmzFy5MOUlpbWt/3xj39ixx13AmD8+Cd59NGxpFJ11NbW0adPP0477UwWL17ERRf9CoBly5by9dfVdOsWzYU44IADOffcX6/1Xm+9NZl77vkLq1atYtWqlVRUdOHPf/4rpaWlpFIp/vGPhxk//kkgRSqVokePvfjVry6ifftokMybb77Ob35zMTfddBsHH/zT+uMOGXI9u+yy6zrrZY0YMZwnn3yMLl3WVO3u1+/nnHjiyfWvVVZWsmzZctq1a8eRR/bluONOpKwsu5UelTxEpFlYtmwZzz03sdGZ3M8+O4FHHx3LbbfdRdeuXVm0aBHXXHM5qVSKM844mwceeAiIEsPQoXcyYsSoRt+jpqaG3/72Cv7yl+HstNPOAEyfPq1+2ZF7772HqVPf4q677qFz5wpKS+Hll19i0aJv65PHmtoh49ZKHhvSu3c/Lrjg4iZfmz37C2688Vpmz56VcV2SjaU+DxFpFgYNOof77vsbq1atWue1ESP+xgUXXEzXrtFihx06dODyy69m1Kj7g+p3LF26lOXLl9G585pl1bt334WSkhKWLl3Kww+P4aqrfkfnzhVAtNrvIYccRlXVNgB8++1CJk/+N9dd91+8++47zJ//9ff5kddRVbUNV199LU8++RhLlixJ9NgNKXmISLOwyy67YrYrTz65dtXqpUu/Y+7c2ey++x5rtW+//Q5ssskmfPHFzIzfo0OHDhx99LGcfPJxXHHFJYwa9QBfffUlAJ99NoNWrTZh2223X+/+zz03kQMPPIjOnSs45JBDefbZCRm977PPTuCMM06p/3rzzdfXu+12223PpptuysyZn2X8c20MJQ8RaTbOOed8xowZydKlSzPafmPW9rv00iu5//4xHHTQIUyb9j4DB57ErFkzyeRQEyY8Rd++RwPQp89RTJgwPqP37N27Hw888FD91wEH/CQ47qTlrM/DzLoDI4EKYD4w0N0/arDNg0CPtKYewLHuntkZzoL2HTZj09bqGhIpBttuuz0HHHAgjzwypr6tTZu2bLVVFe+//y777//j+vbPPvuUmpoaqqq6Bb9PVdU2VFVtw9FHH8tll13IG2+8ys9/fhwrV65k5szP2XbbdReNnDbtAz77bAY333xDfdvXX1fz7rtvs8ceewbHsD4zZ37G8uXL2W677RM7ZmNy+ak4DBjq7qPNbAAwHDgsfQN3H7j6sZntCbwEPJfDGNexaevyrKwCKyLZMWjQOZx11mnU1tamtf0nQ4f+mR122JEtt4w6zG+77WYGDDiD1q0zH2K8dOlS3nvvHfbddz9KSkpYvHgxc+fOZqutqmjTpg2//OUp/PGPQ7jxxlvo1KkzqVSK559/ht1334Onnx7Pqaeezjnn/Kr+eKNG3c+ECeMTSx5z587h5ptv5Be/OIG2bdslcsz1yUnyMLMtgJ6sqU8+FrjbzCrdvXo9u50FjHH3FbmIUUQ2Xs3KFfGw2uSPG2qLLbbkyCP78vDDo+vb+vQ5ihUrlnPZZYNJpVLU1tbSu3c/Bg4cFHj0FE888Sh/+tMfadWqNbW1tfTq1YdDDjkUgHPP/TWPPDKGwYPPjbZOpejR44fsvfe+/Otfz3PPPSPWOtoRR/Tm9NNP5qKLLgfg3nuHMXr0yPrXr7jiGiDq85g8eVJ9+09+cjBnn31e/Wv/7/9NYvny5bRt245evXoHlMfdeDmp52FmewMPuvvuaW0fAAPc/a1Gtm8FzAF+5u5TM3yb7YFPEwh3Hdm48sjO2lbFQVdyxe/99z9g661Vz6PYzJnzObvvvtv6Xg6q5xF85WFm3YAqd//f0H0DHAvMDEgc9ZIuBpX06rfZVAwFkbJ1PovhZy8GmRaDqqurK6giR4Wq0IpB1dXVrfP7TSsGFSTj0VZmtq2ZvQFMA16M204ws79nsPssoMrMyuL9yoCt4/bGDALuyzQ2ERHJrZChusOBCUB7YPUsnBdY04+xXu4+D5gK9I+b+gNTGuvvMLNtgIOAhwJiE5Eca0YlrFuEpH9fIcnjR8At7l4HpADc/Vtg8wz3Pw8YbGbTgcHxc8xsopntk7bd6cBT7v5NQGwikkPl5a347rtFSiBFIpVK8d13iygvb5XYMUP6PL4CdgKmr24ws92AjKZnuvs0YL9G2vs2eD4kICYRyYNOnSpZsKCaJUsW5juUglZaWkpdXWH0eZSXt6JTp8qmN8z0eAHb3gY8bWY3A+Vm1h+4BrglsWhEpCiUlZXTpctW+Q6j4GU6AKEYZXzbyt3vA64ATiTq6B4I/N7dx2xwRxERaXYyuvKIR0ddBwxx939mNyQRESl0GV15uHst8GvWjLISEZEWLGS01UjiEVIiItKyhXSY/4hoqO0VRH0e9WP03P3gpAMTEZHCFZI87o2/RESkhcs4ebj7yKa3EhGRliBoYUQzOxM4DagCZgOj3P3+bAQmIiKFK+PkYWa/JZrbcTvwObAdcIWZba1Z4SIi66qrWZn4StI1K1ew4NuViR5zY4RceZwN/NTdP1/dYGbPAa8CSh4iIg2UlrfKUu2e/CePkKG6bYGGq+DOBzZLLhwRESkGIVcezwJjzOwqosUQtyO64shrjXEREcm9kCuPC4DFwNvAEqL6HN8RLa8uIiItSMhQ3UXAQDM7A+gCfB3X9hARkRYmZLTVQGCqu78DzIvb9gR6uPuoLMUnIiIFKKTP40ZgrwZts4DxgJKHiBS19h02Y9PWQVPfWrSQM9UBWNSg7VugYyY7m1l3osUVK4hGaQ10948a2e6XwO+BEqL1s37m7l8FxCkiEmzT1uUcfdm4RI/51O3HJHq8QhLSYf4B0HDA8i+ADzPcfxgw1N27A0OB4Q03iGuZXw8c4e4/AH5ClKBERKSAhFx5XAlMNLOTgE+I6pkfDvTd4F6AmW0B9ASOiJvGAnebWaW7p88duQS4zd2/BHB3JQ4RkQIUMtrqdTP7AXAK0A2YBFzk7rMy2L0bMDsuKoW715rZnLg9PXnsBnxqZq8C7YAniKoXphoecH0qKtplummzk/QyCMWkJf/sSdO5LHyF8DsK6h1y95nALQBmthlQm4V4ehBdobQimpg4E3gw0wPMn7+EurqMc02TCuGXlKnq6sX5DqFJ2TqfxfCzF4PKyvYt9ly21P/rpaUlG/VHd8Z9HmZ2m5n9KH7cD/gGWGhmR2ew+yygKq6Fvrom+tZxe7rPgcfcfYW7LwbGERWhEhGRAhLSYX4q8F78+FpgAPBz4KamdnT3eUQz0vvHTf2BKQ36OwAeAnqZWYmZbULUp/J2QIwiIpIDIcmjjbsvNbMKYEd3f9zdXyRa4yoT5xGVsZ1OtKTJeQBmNjEeZQXwMNEExA+Iks37wIiAGEVEJAdC+jymm9mpRKOsXgAwsy7Askx2dvdpwH6NtPdNe1wHXBp/iYhIgQpJHr8C7iRaSP6suO1I4PmkgxIRkcIWMlT338CPG7SNAcasfm5mV7n7LcmFJyK51Jwr30mykl7I5RriobwiUnyac+U7SVZIh3kmShI+noiIFKCkk0dys/NERKRgJZ08RESkBUi6z0O3rURyRPUnJJ+S/pf3WsLHE5H1UP0JyaeQMrRTiIo5jV1fcab0CX8iuaLhpSK5F3Ll8V9E61sNiZdMHwU86e4ZzTAXyRYNLxXJvYw7zOO1rI4jqsExjmjG+Vwzu8/MDstWgCIiUniCR1u5+zdE9TWGEdXaOB74m5lNN7OfJRyfiIgUoJA+j1KiIk2nAUcBbxLNJn/S3ZeZ2fHAaKBrNgIVEZHCEdLnMQf4muiq4wp3n5P+ors/bmYXJBmciIgUppDkcZS7T97QBu5+6PeMR0REikBIn8duZtYjvcHM9jSz0xKOSUREClxI8riRdWuOzyIawisiIi1IyG2rDsCiBm3fAh0z2dnMuhNNMqwA5gMD3f2jBttcTzQEeHV/yhvu/uuAGEVEJAdCkscHRMNyH01r+wXwYYb7DwOGuvtoMxsADAcamx/yoLtfHhCXiIjkWEjyuBKYaGYnAZ8Q1TI/HGhySRIz2wLoSTTUF2AscLeZVbp7dVjIIiKSbyFlaF83sx8ApxDNMp8EXOTuDftBGtMNmO3utfGxas1sTtzeMHmcbGa9gC+B69z9zUxjBKioaBeyebOS9PpOLZ3OZ3J0LpNVCOczaFVdd59JdsvMDgOGuPsqMzsCGGdmu7r7/EwPMH/+EurqkqtJVQi/pExVVy/OdwhN0vlMjs5lslrq+SwtLdmoP7qDkoeZ/Rw4BOhCWu0Odx/YxK6zgCozK4uvOsqArWkwesvdv0x7/IKZzQJ+ALwSEqeIiGRXxkN1zew6ok7uUuBEohFTRwILm9rX3ecBU4H+cVN/YErD/g4zq0p7vBewPeCZxigiIrkRMs9jEHCEu18CrIy/H030AZ+J84DBZjYdGBw/x8wmmtk+8TY3mdl7ZvY2cC9wWvrViIiIFIaQ21Yd3f29+PFKM9vE3SeZ2SGZ7Ozu04D9Gmnvm/b49IB4REQkT0KuPD4xs93jx+8B58dLkyxIPiwRESlkIVcevyOaHQ5wFfAQ0I5oRriIiLQgGSWPuJbHcuB/Adx9EtEkQRERaYEyum3l7nXAOHdXUWcREQnq83jVzPbPWiQiIlI0Qvo8PgeeMbNxRJP76qdxu/u1SQcmIiKFKyR5bAb8M368TRZiERGRIhGyMOKZ2QxERESKR8bJw8x2XN9r7j4jmXBERKQYhNy2+pion6MkrW11v0dZYhGJiEjBC7lttdbILDPrClwHvJZ0UCIiUthChuquJV6w8GLg5uTCERGRYrDRySNmQJskAhERkeIR0mH+GmlzO4iSxu7ADUkHJSIihS2kw/zvDZ5/B7zt7h8lGI+IiBSBkA7zkdkMREREikdIGdonzOygBm0HmdljyYclIiKFLOS21SFEtcvTvcmaJUs2yMy6AyOJaoLMBwau75aXmRkwBfiru18eEKOIiORAyGir5UDbBm3tgFUZ7j8MGOru3YGhwPDGNjKzsvi1jJKSiIjkXkjyeA4YbmYdAOLvdwPPNrWjmW0B9ATGxk1jgZ5mVtnI5lcBTwPTA2ITEZEcCrltdRkwGvjGzL4BOgPPAKdlsG83YLa71wK4e62ZzYnbq1dvZGY9gCOBQ4HfB8RWr6Ki3cbs1ixUVrbPdwjNis5ncnQuk1UI5zNktNUCoF+8LEk3YFY8yzwRZrYJcC9wZpxcNuo48+cvoa4u1fSGGSqEX1KmqqsX5zuEJul8JkfnMlkt9XyWlpZs1B/dIZMEewGfuft04Mu4zYBt3f2FJnafBVSZWVmcGMqAreP21bYC/gOYGCeOjkCJmXVw93My/olERCTrQm5bDQUObtC2OG7vvqEd3X2emU0F+hPd+uoPTHH36rRtZgJdVj83s+uBdhptJSJSeEI6zLdw97kN2uYCXTPc/zxgsJlNBwbHzzGziWa2T0AcIiKSZyFXHjPM7DB3fymt7afAp5ns7O7TgP0aae+7nu2vD4hNRERyKCR5XA88YWYjgE+I+ifOjL9ERKQFyfi2lbuPA3oRTRTsF38/Mm4XEZEWJOTKA3efBEzKUiwiIlIkgpKHme0FHEQ0Kqq+lrm7X5twXCIiUsBCVtU9B3gDOAy4EtiDaNb5TtkJTUREClXIUN0rgN7u/gtgWfz9BDJfGFFERJqJ0Hker8WP68ys1N2fAY7OQlwiIlLAQpLHF2a2ffx4OnBMXBxqZeJRiYhIQQvpMP8jsCvwGXAD8BjQCrgw+bBERKSQhayq+0Da42fMrBPQyt2XrG43swPd/Y1kQxQRkUITNFQ3nbuvZN1bVs8AHb5XRCIiUvBC+jwyUdL0JiIiUuySTh7JVWESEZGClXTyEBGRFkDJQ0REgqnPQ0REgm1wtJWZZZRc3L0u/l48FeRFRGSjNTVUt4bMOsHLmtrAzLoDI4EKYD4w0N0/arDNmcAlQF18zHvd/a4M3l9ERHKoqSuLHYAd46/BwCtAb6KZ5r2Bl4ELMnyvYcBQd+8ODAWGN7LN48Ce7r4X8GPgMjPrkeHxRUQkRzZ45eHun69+bGaXAvu4+8K4abqZTQYmA/ds6DhmtgXQEzgibhoL3G1mle5enfZ+i9J2awNsgob/iogUnJAZ5psTfaAvTGtrE7c3pRsw291rAdy91szmxO3V6Rua2c+Bm4lqpF/t7u8GxEhFRbuQzZuVykp1OSVJ5zM5OpfJKoTzGZI8RgIvmtmfgVlEH/wXxu2JcffxwHgz2xb4p5lNdHfPdP/585dQV5fcxUoh/JIyVV29ON8hNEnnMzk6l8lqqeeztLRko/7oDi0GdRdwEnAHcDJwd9zelFlAlZmVAcTft47bG+XuM4nqpR8VEKOIiORAyKq6dUSd3sNC38Td55nZVKA/MDr+PiW9vwPAzHZx92nx4y7AocAToe8nIiLZlXHyMLMS4GyiK45Kd+9hZgcDXd390QwOcR4w0syuBRYAA+PjTgSudffJwLlm1ouotG0JcLe7Px/0E4mISNaF9HncQDRa6s+sufr4AvgT0GTyiK8o9mukvW/a40sC4hERkTwJ6fM4AzjK3R9mzfDZT4nmgIiISAsSkjzKgNVVA1cnj3ZpbSIi0kKEJI+JwB1m1hrq+0BuBJ7KRmAiIlK4QpLHpUTDa78lmhi4BNgOuDILcYmISAELGaq7CDg2XmpkO2CWu3+ZtchERKRghQzV7QV85u7TgXlxmwHbuvsLWYpPREQKUMhtq6FAwznxi+N2ERFpQUKSxxbuPrdB21yga4LxiIhIEQhJHjPM7LAGbT8lmushIiItSMgM8+uBJ8xsBPAJ0ZLpZ8ZfIiLSgmR85eHu44BeQFugX/z9yLhdRERakJArD9x9EtEy6SIi0oKFDNVtRbS+1V5Ey5LUc/eByYYlIiKFLLSS4J5Ey5F8lZ1wRESkGIQkj97ADu6+sMktRUSkWQsZqjsTaJ2tQEREpHiEXHk8CIwzsztpcNvK3V9KNCoRESloIcnjgvj7TQ3aU2RQEMrMuhP1m1QA84GB7v5Rg21+T1Tmtib+usbdnwuIUUREciBkVd0dvud7DQOGuvtoMxsADAcazlifBNzu7kvNbE/gFTPbyt2Xfc/3FhGRBIX0eWy0eBn3nsDYuGks0NPMKtO3c/fn3H1p/PQdoIToSkVERApIyDyPDkRLlBwCdCH6YAfA3bdtYvduwGx3r423rzWzOXF79Xr2GQh84u5fZBqjiIjkRkifx1+BbYAbgNHAAOA3wONJB2VmhxCVuD0idN+KinZNb9RMVVa2z3cIzYrOZ3J0LpNVCOczJHn0AnZ19/lmVuvu48xsMtGkwT81se8soMrMyuKrjjKikrazGm5oZgcQJadj3N0D4gNg/vwl1NWlQndbr0L4JWWqurphuZXCo/OZHJ3LZLXU81laWrJRf3SH9HmUEtUvB1hiZh2J6nns1NSO7j4PmAr0j5v6A1Pcfa1bVma2L/AIcIK7vxUQm4iI5FDIlcfbRP0d/wJeI6oguASYnuH+5wEjzexaYAFRnwZmNhG41t0nE90a2wwYHlW4BeA0d383IE4REcmykOTxn6zpJL8QuBnoSJwEmuLu04D9Gmnvm/Z434B4REQkT0LmecxIe1wNnJ2ViEREpOBtMHmY2aBMDuLu9yUTjoiIFIOmrjxOy+AYKUDJQ0SkBdlg8nD3Q3MViIiIFI+gMrSrmVkJa88wr0ssIhERKXghy5NUAXcDBxONskpXlmRQIiJS2EImCQ4DVgKHE83v6AmMJ5q/ISIiLUhI8vgxMMjdpwIpd38bOAu4LCuRiYhIwQpJHrVEBZoAFsbLqX8HVCUelYiIFLSQ5PF/wOrZ4M8RrUH1BDA56aBERKSwhYy2Oo01I6wuAi4H2gF3Jh2UiIgUtpArj6XAJWb2EVEN8tOJbmMtyEZgIiJSuEKSxz1ENccvBPaNvx9MtBKuiIi0ICG3rY4F/sPdF8bPPzCz/wM+BjJaA0tERJqHkCuPL4E2Ddo2IyoIJSIiLUhTq+oelvZ0FPCsmf0F+ALoBvwaeDB74YmISCFq6rbViEbarmnw/Fzgv5MJR0REikFTq+rukKtARESkeGzUqrobw8y6AyOBCqKhvgPd/aMG2/QCbgL2AP7i7pfnKj4REclcSIf59zUMGOru3YGhwPBGtplBVCv91hzGJSIigXKSPMxsC6JVeMfGTWOBnvH6WPXc/WN3n8KaNbRERKQA5eq2VTdgtrvXArh7rZnNidurk3yjiop2SR6uqFRWts93CM2KzmdydC6TVQjnM2d9Hrkyf/4S6upSiR2vEH5JmaquXpzvEJqk85kcnctktdTzWVpaslF/dOeqz2MWUGVmZQDx963jdhERKTI5SR7uPg+YCvSPm/oDU9w90VtWIiKSG7m8bXUeMNLMriVaiXcggJlNBK5198lm9hPgYaADUGJmJwNnuftzOYxTRESakLPk4e7TgP0aae+b9vh1YJtcxSQiIhsnl/M8RESkmVDyEBGRYEoeIiISTMlDRESI3j35AAAHKklEQVSCKXmIiEgwJQ8REQmm5CEiIsGUPEREJJiSh4iIBFPyEBGRYEoeIiISTMlDRESCKXmIiEgwJQ8REQmm5CEiIsGUPEREJJiSh4iIBMtZJUEz6w6MBCqA+cBAd/+owTZlwF1AbyAF3OLuf89VjCIikplcXnkMA4a6e3dgKDC8kW1OBXYCdgYOAK43s+1zFqGIiGQkJ1ceZrYF0BM4Im4aC9xtZpXuXp226UnAve5eB1Sb2T+BE4FbM3ibMoDS0pLkAo9t0WmzxI9Zvnll4sfMxs+eDTqfydG5TFZLPJ9pxyoL2a8klUolFsT6mNnewIPuvnta2wfAAHd/K63tXWCQu/87fn4FsI27X5jB2/wEeC3ZyEVEWoyDgNcz3ThnfR458G+iH34uUJvnWEREikUZsBXRZ2jGcpU8ZgFVZlbm7rVxx/jWcXu6mcB2rPkhtgU+z/A9VhCQNUVEpN4noTvkpMPc3ecBU4H+cVN/YEqD/g6AfwD/aWalZlYJHAs8nosYRUQkc7kcbXUeMNjMpgOD4+eY2UQz2yfeZhQwA/gI+F/gBnefkcMYRUQkAznpMBcRkeZFM8xFRCSYkoeIiART8hARkWBKHiIiEkzJQ0REgil5iIhIMCWPHDGzinzHICKSFM3zyDIzOwx4hKiOySzgWHefkt+oipOZnQz8290/iZ//FTgF+JRokc338xlfsTGzPwAvA2+6+4p8xyPFRVce2XcrcBbQFrgOuCm/4RS1a4gWvsTMjgH6Ab2AvwF/ymNcxaoz8BfgGzN72cyuM7ODzaxVvgMrRmb2QNrj3zV47emcB5RlSh7ZV+bu4919mbs/AHTNd0BFLOXuS+PHvYH73X2Su98DbJHHuIqSuw929z2IFiO9G+hCVKjtGzP7V16DK0490h4f1+C1qlwGkgvNaUn2gmVmmwGrK66UpD9P+zCUpqUXq/kxcNl6XpMA7v61mT0HLIu/jgW2yW9URalkPY8hKqvdrCh5ZF8PYAlr/2Na/TyFPvRCvGJmY4Evif5KfhXqK1WuymdgxcjM+gA/BQ4BWgNvEBVUu8Pdv8xjaMUqtZ7HzZKSR5a5u24NJucS4AqixHGku6+M27sDd+QtquI1gXj1auDZuPyzbDwzs0mNPC4h+jfarCh55IiZbQLsHD/9OO2DTzI3BHB3/68G7T3RbZaNsQfRVcfpwJ1m9jHwCvA/RKPaVJEzTN8NvLZlzqLIEQ3VzTIzKyEaJXQNsJLor5By4GZ3H5LP2IqNmb0P9Gj4oWZmpcA77v6D/ETWPJjZLsDhRPV2tnb3DnkOqeiYWVeizvG33b0mLmp3NXCmu3fKb3TJ0i2V7LsaOALY2907uXtHYF/gZ2Z2TX5DKzp1jf01HN9u0S2XjRBX7dzXzH4D3E40lLw1quAZzMzOIiqbPQGYYmb9iArbVQH7bGjfYqTkkX0DgWPcfdrqBnf/kGgo3+l5i6o4tTKzNg0bzawd0QeeBDCzicACovLPewCPAXu5+w7ufmZegytOlwI93b0rUaXUJ4Gz3f2k1RNbmxP1eWRfrbt/27DR3ReYWU0+AipijwAjzewsd18EYGabA8OJPgAlzOPA4Ob4wZYnq1avcuDub5jZDHd/LN9BZYuSR/alzKzK3WenN5qZOnjD3QA8AMw2s4/itp2B8cD1eYqpaLn7iIZtZlYFnAGc4e47r7OTbEgrM9uVNcPy69Kfu/sHeYssC5Q8su9O4FkzuxT4v7htf+C2+DXJkLvXAAPMbCfgh0T/Kd9y94/zG1lxi0cCHkO0jM5PiRL0oDyGVKzaABMbtK1+ngJ2zG042aXRVjlgZqcR/WW8A9E/ok+BG9z9wXzGJS2bmfUgShKnAFOAkUSjALfLa2BSFJQ8ciju2MXdl+Q7FhEzqwP+BQxy91lx2wx3b1Z/IUt26LZVDqUnjfivvuvc/fg8hiQt2wXAmcCr8YqwuhKWjOnKI8vMrDvwZ6AbMBb4KzCMaFXY2xqZLS2SU2a2B2tuX7UHfg08vnpEm0hjlDyyzMxeJuoo/x+iTslDgA+B8919Xh5DE1lLWsf5mcAR7q66HrJeum2VfV3c/SoAM3ueaEXYk+KRQyJ51WA5jVVm9grRcvdH5DcyKXSaYZ599UuFx8tofKHEIYWgieU0ds1nbFL4dNsqy8zsOyC9tvbu6c/d/Uc5D0qE+oUmf+nu75vZgUT1zE9pzrOiJTm6bZV9xxCtu9RweG47YEXuwxGp16KW05BkKXlk35FENSj+nt5oZhcS1aB4MS9RibSw5TQkWUoe2dcXuKqR9qHA20SV8UTyoUUtpyHJUvLIvvXVoKiNZ/iK5IW7b5/vGKR4abRV9qkGhYg0O0oe2be6BkV9Sc+4BsXfUQ0KESlSum2VfapBISLNjuZ55IhqUIhIc6LkISIiwdTnISIiwZQ8REQkmJKHiIgEU/IQEZFg/x9BRIaIOYmsjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "joint_results.plot.bar() \n",
    "plt.ylabel(sklearn_metric.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Your final answers to question 3:</a></b> Does rescaling always help? In which case does it help most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3145198580879243\n",
      "-1.3145198580879243\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background:#00FF00\">CORRECT<br>:-)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put your answer to question 3 here\n",
    "rescaling_always_help = 0 # 0 for false, 1 for true\n",
    "varnum_rescaling_helps_most = -1 # num of var (0-based) for which perf. improve most after rescaling\n",
    "case_num_rescaling_helps_most = 2 # num of case (0-based) for which perf. improve most after rescaling\n",
    "\n",
    "# This is the checker code, keep it\n",
    "question = 3\n",
    "answer = (p_tr+s_tr+p_te+s_te)/10\n",
    "answer += joint_results.sum().sum()/10-rescaling_always_help-case_num_rescaling_helps_most\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Identify the best model\n",
    "We are now ready to perform systematic experiments on various models. We will use the methods proposed in the variable `classifiers` of <a href=\"https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\">these scikit-learn examples</a>, compare classifier performances on the dataset `CS_SCALED`:\n",
    "\n",
    "### Question 4: Overfitting and underfitting\n",
    "\n",
    "</b> There may be two reasons why a model performs poorly. It could either be <b>overfitting</b> or <b>underfitting</b> data. \n",
    "\n",
    "First you will perform these steps (with some help):\n",
    "\n",
    "* Create a variable `data_df` and assign to it the data frame of the scaled version of the CS dataset.\n",
    "* Create a variable `model_name` and a variable `model_list` containing the list of model names and the list of models (classifiers) from the <a href=\"https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\">the scikit-learn examples</a> we pointed you to.\n",
    "* Call `systematic_model_experiment(data_df, model_name, model_list, sklearn_metric)` and display the results. \n",
    "* Find which method performs best. <b>Tip:</b> Use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.idxmax.html#pandas.Series.idxmax\">idxmax</a>.\n",
    "* Find which models have TEST performance UNDER THE MEDIAN test performance. The single out models with TRAINING performance UNDER THE MEDIAN and those with TRAINING performance OVER THE MEDIAN.\n",
    "\n",
    "Then answer those questions:\n",
    "* If the test performance is bad but the training performance is good, is the model under-fitting or over-fitting? \n",
    "* If both are bad, is the model is under-fitting or over-fitting? \n",
    "* Which models are over-fitted and which ones are under-fitted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Choose the correct dataset: CS representation, scaled data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491, 14581)\n"
     ]
    }
   ],
   "source": [
    "dataset_choice = 2 # Change that\n",
    "data_df = all_scaled_data_df[dataset_choice] # Change that\n",
    "\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier comparison\n",
    "We import a bunch of classifiers, inspired \n",
    "by <a href=\"https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\">that list</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "model_name = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "model_list = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Systematic experiments:\n",
    "We give you this code to make systematic experiments (run all models on the chosen representation). You may get a warning. What could explain it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow0_col0 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow0_col1 {\n",
       "            background-color:  #2070b4;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow0_col2 {\n",
       "            background-color:  #6aaed6;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow0_col3 {\n",
       "            background-color:  #6aaed6;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow1_col0 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow1_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow1_col2 {\n",
       "            background-color:  #105ba4;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow1_col3 {\n",
       "            background-color:  #6aaed6;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow2_col0 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow2_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow2_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow2_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow3_col0 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow3_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow3_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow3_col3 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow4_col0 {\n",
       "            background-color:  #083877;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow4_col1 {\n",
       "            background-color:  #6aaed6;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow4_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow4_col3 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow5_col0 {\n",
       "            background-color:  #0a539e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow5_col1 {\n",
       "            background-color:  #c6dbef;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow5_col2 {\n",
       "            background-color:  #abd0e6;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow5_col3 {\n",
       "            background-color:  #c6dbef;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow6_col0 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow6_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow6_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow6_col3 {\n",
       "            background-color:  #c6dbef;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow7_col0 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow7_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow7_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow7_col3 {\n",
       "            background-color:  #6aaed6;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow8_col0 {\n",
       "            background-color:  #c1d9ed;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow8_col1 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow8_col2 {\n",
       "            background-color:  #105ba4;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow8_col3 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow9_col0 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow9_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow9_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c336ccfc_4407_11ea_b2da_d89ef318e25erow9_col3 {\n",
       "            background-color:  #2070b4;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25e\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >perf_tr</th>        <th class=\"col_heading level0 col1\" >std_tr</th>        <th class=\"col_heading level0 col2\" >perf_te</th>        <th class=\"col_heading level0 col3\" >std_te</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row0\" class=\"row_heading level0 row0\" >Nearest Neighbors</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow0_col0\" class=\"data row0 col0\" >0.7</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow0_col1\" class=\"data row0 col1\" >0.03</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow0_col2\" class=\"data row0 col2\" >0.56</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow0_col3\" class=\"data row0 col3\" >0.02</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row1\" class=\"row_heading level0 row1\" >Linear SVM</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow1_col1\" class=\"data row1 col1\" >0</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow1_col2\" class=\"data row1 col2\" >0.6</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow1_col3\" class=\"data row1 col3\" >0.02</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row2\" class=\"row_heading level0 row2\" >RBF SVM</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow2_col0\" class=\"data row2 col0\" >1</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow2_col2\" class=\"data row2 col2\" >0.5</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow2_col3\" class=\"data row2 col3\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row3\" class=\"row_heading level0 row3\" >Gaussian Process</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow3_col0\" class=\"data row3 col0\" >1</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow3_col1\" class=\"data row3 col1\" >0</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow3_col2\" class=\"data row3 col2\" >0.5</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow3_col3\" class=\"data row3 col3\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row4\" class=\"row_heading level0 row4\" >Decision Tree</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow4_col0\" class=\"data row4 col0\" >0.99</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow4_col1\" class=\"data row4 col1\" >0.02</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow4_col2\" class=\"data row4 col2\" >0.62</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow4_col3\" class=\"data row4 col3\" >0.04</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row5\" class=\"row_heading level0 row5\" >Random Forest</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow5_col0\" class=\"data row5 col0\" >0.96</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow5_col1\" class=\"data row5 col1\" >0.01</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow5_col2\" class=\"data row5 col2\" >0.54</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow5_col3\" class=\"data row5 col3\" >0.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row6\" class=\"row_heading level0 row6\" >Neural Net</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow6_col0\" class=\"data row6 col0\" >1</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow6_col1\" class=\"data row6 col1\" >0</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow6_col2\" class=\"data row6 col2\" >0.62</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow6_col3\" class=\"data row6 col3\" >0.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row7\" class=\"row_heading level0 row7\" >AdaBoost</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow7_col0\" class=\"data row7 col0\" >1</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow7_col1\" class=\"data row7 col1\" >0</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow7_col2\" class=\"data row7 col2\" >0.62</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow7_col3\" class=\"data row7 col3\" >0.02</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row8\" class=\"row_heading level0 row8\" >Naive Bayes</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow8_col0\" class=\"data row8 col0\" >0.78</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow8_col1\" class=\"data row8 col1\" >0.04</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow8_col2\" class=\"data row8 col2\" >0.6</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow8_col3\" class=\"data row8 col3\" >0.04</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25elevel0_row9\" class=\"row_heading level0 row9\" >QDA</th>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow9_col0\" class=\"data row9 col0\" >1</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow9_col1\" class=\"data row9 col1\" >0</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow9_col2\" class=\"data row9 col2\" >0.5</td>\n",
       "                        <td id=\"T_c336ccfc_4407_11ea_b2da_d89ef318e25erow9_col3\" class=\"data row9 col3\" >0.03</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f17acc7d518>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compar_results = systematic_model_experiment(data_df, model_name, model_list, sklearn_metric)\n",
    "compar_results.round(2).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Find the method performing best on test data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2d8ee0d40a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the method performing best on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# REPLACE THIS; try not to just do this by hand, apply idxmax to the series perf_te\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best method: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compare_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the method performing best on test data\n",
    "best_method = compare_results.perf_te.idxmax() # REPLACE THIS; try not to just do this by hand, apply idxmax to the series perf_te\n",
    "print(\"Best method: {}\".format(best_method))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over-fitting and under-fitting\n",
    "There may be two reasons why a model performs poorly. It could either be <b>over-fitting</b> or <b>under-fitting</b> data. Under-fitting means that the model is not powerful enough to even learn the training data while over-fitting means that the model is so powerful that it can learn super-well the training data, but it might not generalize well to new test data.\n",
    "\n",
    "Of the models performing poorly (having TEST performance UNDER THE MEDIAN test performance), we highlight:\n",
    "* models with TRAINING performance UNDER THE MEDIAN training performance (<b>under-fitted</b>)\n",
    "* models with TRAINING performance OVER THE MEDIAN (<b>over-fitted</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We give you this code, check it in utilities.py of use ??analyze_model_experiments\n",
    "analyze_model_experiments(compar_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar graph comparing  results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'balanced_accuracy_score')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compar_results[['perf_tr', 'perf_te']].plot.bar()\n",
    "plt.ylim(0.5, 1)\n",
    "plt.ylabel(sklearn_metric.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>\n",
    "<b>Your final answers to question 4:</a> </b>Which methods overfits or underfit?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over_fitted models:\n",
      "['Linear SVM', 'Gaussian Process', 'Neural Net']\n",
      "Under_fitted models:\n",
      "['RBF SVM', 'Naive Bayes']\n",
      "7\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background:#FF0000\">BOOOOH<br>:-(</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put your answer to question 4 here\n",
    "#If the test performance is bad but the training performance is good, is the model under-fitting or over-fitting?\n",
    "answer1 = -1 # 0 for under-fitting and 1 for over-fitting\n",
    "#If both are bad, is the model is under-fitting or over-fitting? \n",
    "answer2 = -1 # 0 for under-fitting and 1 for over-fitting\n",
    "# Which models are over-fitted and which ones are under-fitted?\n",
    "overfitted_list = [1,3,6] # Replace by the correct numbers in model_name\n",
    "underfitted_list = [2,8] # Replace by the correct numbers in model_name\n",
    "\n",
    "model_name = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "print(\"Over_fitted models:\")\n",
    "print([model_name[i] for i in overfitted_list])\n",
    "print(\"Under_fitted models:\")\n",
    "print([model_name[i] for i in underfitted_list])\n",
    "# This is the checker code, keep it\n",
    "question = 4\n",
    "answer = answer1-answer2+sum(overfitted_list)-sum(underfitted_list)+model_name.index(best_method)\n",
    "\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 5: Dimensionality reduction\n",
    "It is useful to reduce the data dimension (number of features) for two reasons: ease of visualisation and possibly increase in performance. Two approaches are possible:\n",
    "1. Feature selection.\n",
    "1. Feature transforms.\n",
    "\n",
    "In the first case, one tries to select among the original features. In the second case, one first replaces the original features by \"combinations\" of features, then perform selection. Here we give two simple examples: Feature ranking with the <b>Pearson correlation</b> coefficient (as a feature selection method), and <b>Singular Value Decomposition</b> or SVD (as a feature transform method) .\n",
    "\n",
    "In this section, we keep using the <b>CS scaled data</b>. We use as classifier the <b>3-nearest-neighbor</b> model, which seems to have served us well! We begin by showing you how to do simple feature selection, then we'll guide you step-by-step through SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection example\n",
    "We perform feature selection with the Pearson correlation coefficient as follows:\n",
    "* Compute the correlation matrix (we will only use the last column, i.e. correlation of features with the class label to be predicted)\n",
    "* Sort the correlation coefficients (of features and class label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix\n",
    "If we did things right, `data_df` should contain the CS data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_df.corr()\n",
    "corr.round(1).style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first sort all features by the <b>absolute value</b> of the Pearson correlation coefficient. Indeed, variables are informative no matter whether they are correlated or anti-correlated (since it suffices to multiply them by -1 to change the correlation direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sval = corr['fruit'][:-1].abs().sort_values(ascending=False)\n",
    "ranked_columns = sval.index.values\n",
    "print(ranked_columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the features that we have constructed in the previous lessons 'R-(G+B)/2' and 'W/H' come in the 5 top most informative features. But there are others. Let us make all scatter plots of pairs of features for the 5 top ranked features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize top 5 features with PAIRPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with only top five features\n",
    "fruit_name = ['Banana', 'Apple']\n",
    "fruit_list = [fruit_name[int((i+1)/2)] for i in data_df[\"fruit\"].tolist()]\n",
    "col_selected = ranked_columns[0:5]\n",
    "df_5feat = pd.DataFrame.copy(data_df)\n",
    "df_5feat = df_5feat[col_selected]\n",
    "df_5feat['fruit'] = fruit_list\n",
    "df_5feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show pairplot\n",
    "g = sns.pairplot(df_5feat, hue=\"fruit\", markers=[\"o\", \"s\"], diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curves\n",
    "We want to eveluate the effect of varying the number of features. To that end, we build learning curves = performance as a function of feature number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the 3 nearest neighbor classifier to create the learnign curve\n",
    "sklearn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "feat_lc_df = feature_learning_curve(data_df, sklearn_model, sklearn_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "plt.errorbar(feat_lc_df.index+1, feat_lc_df['perf_tr'], yerr=feat_lc_df['std_tr'], label='Training set')\n",
    "plt.errorbar(feat_lc_df.index+1, feat_lc_df['perf_te'], yerr=feat_lc_df['std_te'], label='Test set')\n",
    "plt.xticks(np.arange(1, 22, 1)) \n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel(sklearn_metric.__name__)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the, with 5 features, it is about as good as it gets, given the error bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition\n",
    "Let us move now to the second way of reducing dimensionality: feature transforms.\n",
    "When we use SVD, the feature transform consists in finding the \"principal directions\"(directions of largest variance). The method is also known as Pricipal Component Analysis (PCA). I simply used my search engine and typed the keywords \"pandas svd\". I found a nice tutorial on <a href=\"https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/\">this page</a> and a step-by-step procedure on <a href=\"https://cmdlinetips.com/2019/05/singular-value-decomposition-svd-in-python/\">this page</a>. \n",
    "\n",
    "We will guide you step-by-step:\n",
    "* Create a dataframe called `df_scaled` containing the standardized columns, except the last one (tip: just use `drop` to eliminate the last column).\n",
    "* Perform a singular value decomposition of `df_scaled` and call the resulting matrices u, s, v.\n",
    "* Make a scree plot of the eigen values (square of the singular values). Save the plot in file 'svd_scree_plot.png'.\n",
    "* Create a new dataframe `svd_df` with the two singular values as columns and the fruit type as index.\n",
    "* Make pairwise scatter plots of the three first singular values.\n",
    "\n",
    "Then the question to answer will be to compute the performances obtained with the 3 nearest neighbor method using the first 3 singular values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make use the CS scaled dataset (this should be already loaded in data_df,\n",
    "# if you did things correctly in previous questions)\n",
    "# To obtain df_scaled, remove the last column of data_df.\n",
    "\n",
    "df_scaled = df_scaled2[{\"redness\", \"elongation\"}] # REPLACE THIS BY THE CORRECT ANSWER\n",
    "\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform singular value decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(df_scaled, full_matrices=True)\n",
    "print('U {}'.format(u.shape))\n",
    "print('S {}'.format(s.shape))\n",
    "print('V {}'.format(v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a scree plot\n",
    "This plot allows us to decide how many components to keep, considering the total variance explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained = np.round(s**2/np.sum(s**2), decimals=3)\n",
    "sns.barplot(x=list(range(1,len(var_explained)+1)),\n",
    "            y=var_explained, color=\"limegreen\")\n",
    "plt.xlabel('SVs', fontsize=16)\n",
    "plt.ylabel('Percent Variance Explained', fontsize=16)\n",
    "plt.savefig('svd_scree_plot.png',dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that after 3 features there is a big drop in variance. So tentatively, let us keep the top three components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only the three first principal components\n",
    "fruit_name = ['Banana', 'Apple']\n",
    "fruit_list = [fruit_name[int((i+1)/2)] for i in df[\"fruit\"].tolist()]\n",
    "fnum=3\n",
    "labels= ['SV'+str(i) for i in range(1,fnum+1)]\n",
    "df_3svd = pd.DataFrame(u[:,0:fnum], columns=labels)\n",
    "df_3svd['fruit'] = fruit_list\n",
    "df_3svd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the pairplot of svd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate df_3svd: \n",
    "This piece of code will serve you later to answer question 5!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the function df_cross_validate that we already used in question 3 to evaluate svd_df\n",
    "df_3svd['fruit'] = df.iloc[:, -1].to_numpy() # We replace the target values by numbers\n",
    "p_tr, s_tr, p_te, s_te = df_cross_validate(df_3svd, sklearn_model, sklearn_metric)\n",
    "metric_name = sklearn_metric.__name__.upper()\n",
    "print(\"AVERAGE TRAINING {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_tr, s_tr))\n",
    "print(\"AVERAGE TEST {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_te, s_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD learning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the learning curve for the 3-nearest neighbor classifier ...\n",
    "sklearn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "feat_lc_df = svd_learning_curve(data_df, sklearn_model, sklearn_metric)\n",
    "\n",
    "# and we plot the learning curve\n",
    "plt.errorbar(feat_lc_df.index+1, feat_lc_df['perf_tr'], yerr=feat_lc_df['std_tr'], label='Training set')\n",
    "plt.errorbar(feat_lc_df.index+1, feat_lc_df['perf_te'], yerr=feat_lc_df['std_te'], label='Test set')\n",
    "plt.xticks(np.arange(1, 22, 1)) \n",
    "plt.xlabel('Number of principal compoments')\n",
    "plt.ylabel(sklearn_metric.__name__)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of dimensionality reduction methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though features 4 and 5 did not seem to explain a lot of additional variance, there seems to be an optimum at 4 or 5 features. Compare the performances of df_5feat and df_5svd (with 5 top components). Is one significantly better then the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Here you need to do something!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5svd = df_3svd # Replace with the correct dataframe having 5 principal components\n",
    "\n",
    "# Put here the code to compute the performances of df_5feat and df_5svd\n",
    "fnum=5\n",
    "labels= ['SV'+str(i) for i in range(1,fnum+1)]\n",
    "df_5svd = pd.DataFrame(u[:,0:fnum], columns=labels)\n",
    "df_5svd['fruit'] = df.iloc[:, -1].to_numpy() # Need numeric values\n",
    "p_tr_5svd, s_tr_5svd, p_te_5svd, s_te_5svd = 0,0,0,0 # REPLACE THIS\n",
    "p_tr_5feat, s_tr_5feat, p_te_5feat, s_te_5feat = 0,0,0,0 # REPLACE THIS\n",
    "\n",
    "print(\"5FEAT AVERAGE TRAINING {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_tr_5feat, s_tr_5feat))\n",
    "print(\"5FEAT AVERAGE TEST {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_te_5feat, s_te_5feat))\n",
    "print(\"5SVD AVERAGE TRAINING {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_tr_5svd, s_tr_5svd))\n",
    "print(\"5SVD AVERAGE TEST {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_te_5svd, s_te_5svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does one method give significantly better results than the other?\n",
    "answer = -1 # One for yes and 0 for no\n",
    "\n",
    "# This is the checker code, keep it\n",
    "question = 5\n",
    "answer = 0.001*(p_te_5feat-p_te_5svd)/(s_te_5feat+s_te_5svd)\n",
    "score += check(answer, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your final score is 5 / 5, congratulations!\n"
     ]
    }
   ],
   "source": [
    "print('Your final score is %d / 5, congratulations!' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<span style=\"color:red\">\n",
    "<br>\n",
    "    To finalize your homework:\n",
    "<b>\n",
    "<ul>\n",
    "    <li> Use  Kernel + Restart and Run all.</li>\n",
    "    <li> Save your notebook.</li>\n",
    "    <li> Push your changes to your GitHub repo with:</li>\n",
    "</ul>   \n",
    "</b>\n",
    "<pre>\n",
    "git add .\n",
    "git commit -m 'my homework is done'\n",
    "git push\n",
    "</pre>\n",
    "<br>\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
